{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубокая нейронная сеть для классификации изображений: на основе pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from dnn_app_utils_v3 import load_data\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-слойная нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (209, 12288)\n",
      "test_x's shape: (50, 12288)\n",
      "train_y's shape: (209, 1)\n",
      "test_y's shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "train_x_flatten = train_x_orig.reshape(-1, 64 * 64 * 3) \n",
    "test_x_flatten = test_x_orig.reshape(-1, 64 * 64 * 3)\n",
    "\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "train_y = train_y.reshape(-1, 1)\n",
    "test_y = test_y.reshape(-1, 1)\n",
    "\n",
    "train_x = train_x.astype(dtype=np.float32)\n",
    "test_x = test_x.astype(dtype=np.float32)\n",
    "train_y = train_y.astype(dtype=np.float32)\n",
    "test_y = test_y.astype(dtype=np.float32)\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))\n",
    "print (\"train_y's shape: \" + str(train_y.shape))\n",
    "print (\"test_y's shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(train_x)\n",
    "y_train = torch.from_numpy(train_y)\n",
    "\n",
    "x_test = torch.from_numpy(test_x)\n",
    "y_test = torch.from_numpy(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([209, 12288]) torch.Size([209, 1]) torch.Size([50, 12288]) torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=0, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-слойная нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Архитектура нейросети "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 64 * 64 * 3\n",
    "hidden_size = 7\n",
    "output_size = 1\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.0075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=12288, out_features=7, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=7, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = nn.Sequential(nn.Linear(input_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, output_size), nn.Sigmoid()) \n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.0251\n",
      "Epoch [1000/5000], Loss: 0.0110\n",
      "Epoch [1500/5000], Loss: 0.0015\n",
      "Epoch [2000/5000], Loss: 0.0013\n",
      "Epoch [2500/5000], Loss: 0.0014\n",
      "Epoch [3000/5000], Loss: 0.0025\n",
      "Epoch [3500/5000], Loss: 0.0012\n",
      "Epoch [4000/5000], Loss: 0.0008\n",
      "Epoch [4500/5000], Loss: 0.0013\n",
      "Epoch [5000/5000], Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in train_loader:\n",
    "    \n",
    "    outputs = model1(images)\n",
    "    \n",
    "    predicted, _ = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.round() == labels.ravel()).sum()\n",
    "\n",
    "print('Accuracy of the model on the train images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 72.0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    outputs = model1(images)\n",
    "    \n",
    "    predicted, _ = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.round() == labels.ravel()).sum()\n",
    "\n",
    "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-слойная нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "train_x_flatten = train_x_orig.reshape(-1, 64 * 64 * 3) \n",
    "test_x_flatten = test_x_orig.reshape(-1, 64 * 64 * 3)\n",
    "\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "train_y = train_y.reshape(-1, 1)\n",
    "test_y = test_y.reshape(-1, 1)\n",
    "\n",
    "train_x = train_x.astype(dtype=np.float32)\n",
    "test_x = test_x.astype(dtype=np.float32)\n",
    "train_y = train_y.astype(dtype=np.float32)\n",
    "test_y = test_y.astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(train_x)\n",
    "y_train = torch.from_numpy(train_y)\n",
    "\n",
    "x_test = torch.from_numpy(test_x)\n",
    "y_test = torch.from_numpy(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Архитектура нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=12288, out_features=20, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=20, out_features=7, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=7, out_features=5, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=5, out_features=1, bias=True)\n",
       "  (7): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 64 * 64 * 3\n",
    "hidden_size_1 = 20\n",
    "hidden_size_2 = 7\n",
    "hidden_size_3 = 5\n",
    "output_size = 1\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.0075\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear(input_size, hidden_size_1), nn.ReLU(), nn.Linear(hidden_size_1, hidden_size_2), nn.ReLU(),\n",
    "                    nn.Linear(hidden_size_2, hidden_size_3), nn.ReLU(), nn.Linear(hidden_size_3, output_size), nn.Sigmoid())\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.3583\n",
      "Epoch [1000/5000], Loss: 0.0502\n",
      "Epoch [1500/5000], Loss: 0.0400\n",
      "Epoch [2000/5000], Loss: 0.0231\n",
      "Epoch [2500/5000], Loss: 0.0165\n",
      "Epoch [3000/5000], Loss: 0.3965\n",
      "Epoch [3500/5000], Loss: 0.0179\n",
      "Epoch [4000/5000], Loss: 0.0173\n",
      "Epoch [4500/5000], Loss: 0.0237\n",
      "Epoch [5000/5000], Loss: 0.4142\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 98.08612060546875 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in train_loader:\n",
    "    \n",
    "    outputs = model2(images)\n",
    "    \n",
    "    predicted, _ = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.round() == labels.ravel()).sum()\n",
    "\n",
    "print('Accuracy of the model on the train images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 74.0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    outputs = model2(images)\n",
    "    \n",
    "    predicted, _ = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.round() == labels.ravel()).sum()\n",
    "\n",
    "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
