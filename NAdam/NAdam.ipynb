{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb335517",
   "metadata": {},
   "source": [
    "# NAdam (Nesterov-accelerated adaptive momentum)\n",
    "\n",
    "## Немного предыстории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe5d1",
   "metadata": {},
   "source": [
    "## Градиентный спуск (SGD - Stochastic gradient descent)\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot g_t\n",
    "\\end{equation} \\\n",
    "**Проблемы:** застревание в локальных минимумах; возможные сильные колебания при движении к точке минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e804dac",
   "metadata": {},
   "source": [
    "## Метод импульсов\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "m_t = \\gamma m_{t - 1} + (1 - \\gamma) \\eta g_t, \\mspace{2mm} 0 < \\gamma < 1\n",
    "\\end{equation} \n",
    "или, переобозначив $\\eta = (1 - \\gamma) \\eta$, получим\n",
    "\\begin{equation}\n",
    "m_t = \\gamma m_{t - 1} + \\eta g_t \\\\\n",
    "\\theta_{t+1} = \\theta_t - m_t \\\\\n",
    "\\theta_{t+1} = \\theta_t - (\\gamma m_{t - 1} + \\eta g_t)\n",
    "\\end{equation} \\\n",
    "**Преимущества:** при попадании в небольшой локальный минимум градиент мгновенно не обнулится, продолжится движение к глобальному минимуму; сглаживается градиент, уменьшаются амплитуды его случайных изменений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe346a",
   "metadata": {},
   "source": [
    "## Стохастический градиент с импульсом Нестерова (NAG - Nesterov's accelerated gradient)\n",
    "\\begin{equation}\n",
    "m_t = \\gamma m_{t - 1} + \\eta g_t \n",
    "\\end{equation}\n",
    "![](image.png)\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t - \\gamma m_{t - 1}) \\\\\n",
    "m_t = \\gamma m_{t - 1} + \\eta g_t  \\\\\n",
    "\\theta_{t+1} = \\theta_t - m_t\n",
    "\\end{equation} \\\n",
    "**Преимущества:** как правило, показывает лучшую сходимость к точке минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca5f77",
   "metadata": {},
   "source": [
    "## Modified NAG\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "m_t = \\gamma m_{t - 1} + \\eta g_t \\\\\n",
    "\\theta_{t+1} = \\theta_t - (\\gamma m_{t} + \\eta g_t)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c44ab",
   "metadata": {},
   "source": [
    "## RMSProp (running mean square)\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "v_t = \\alpha v_{t - 1} + (1 - \\alpha)g_t^2 \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{g_t}{\\sqrt{v_t} + \\varepsilon}\n",
    "\\end{equation} \\\n",
    "**Преимущества:** нормализация скорости изменения вектора весов, что позволяет увеличить скорость сходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052ca06",
   "metadata": {},
   "source": [
    "## Adam (adaptive momentum)\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "m_t = \\beta_1 m_{t - 1} + (1 - \\beta_1) g_t; \\mspace{5mm} \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} \\\\\n",
    "v_t = \\beta_2 v_{t - 1} + (1 - \\beta_2)g_t^2; \\mspace{5mm} \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\varepsilon}\n",
    "\\end{equation} \\\n",
    "**Преимущества:** ускорение сходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a53212",
   "metadata": {},
   "source": [
    "# NAdam (Nesterov-accelerated adaptive momentum)\n",
    "\\begin{equation}\n",
    "g_t = \\nabla _{\\theta_t}L(\\theta_t) \\\\\n",
    "m_t = \\beta_1 m_{t - 1} + (1 - \\beta_1) g_t \\\\\n",
    "v_t = \\beta_2 v_{t - 1} + (1 - \\beta_2)g_t^2; \\mspace{5mm} \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\varepsilon} \\left(\\frac{\\beta_1}{1 - \\beta_1^{t+1}} m_{t} + \\frac{1 - \\beta_1}{1 - \\beta_1^t}g_t \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cceb26",
   "metadata": {},
   "source": [
    "**Как мы получили NAdam из Adam:** \\\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\varepsilon} = \\\\\n",
    "= \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\varepsilon} \\cdot \\frac{m_t}{1 - \\beta_1^t} = \\\\\n",
    "= \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\varepsilon} \\left(\\frac{\\beta_1}{1 - \\beta_1^{t}} m_{t - 1} + \\frac{1 - \\beta_1}{1 - \\beta_1^t}g_t \\right) = \\\\\n",
    "= \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\varepsilon} \\left(\\frac{\\beta_1}{1 - \\beta_1^{t+1}} m_{t} + \\frac{1 - \\beta_1}{1 - \\beta_1^t}g_t \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b868b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.NAdam(model.parameters(),\n",
    "                  lr = 0.002, \n",
    "                  betas = (0.9, 0.999), \n",
    "                  eps = 1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d346a002",
   "metadata": {},
   "source": [
    "# COSINEANNEALINGLR lr_scheduler\n",
    "\\begin{equation}\n",
    "\\eta _t = \\eta _{\\min} + \\frac{1}{2}(\\eta _{\\max} - \\eta _{\\min}) \\left(1 + \\cos \\left(\\frac{T_{cur}}{T_{\\max}} \\pi \\right) \\right) \\\\\n",
    "\\eta _{t + 1} = \\eta _t + \\frac{1}{2}(\\eta _{\\max} - \\eta _{\\min}) \\left(1 - \\cos \\left(\\frac{1}{T_{\\max}} \\pi \\right) \\right) \n",
    "\\end{equation} \\\n",
    "$\\eta _{\\max}$ - исходный параметр обучения; $T_{\\max}$ - число эпох, после которого происходит обновление параметра обучения; $T_{cur}$ - число эпох, прошедших с момента обновления параметра обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43047ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                           T_max, \n",
    "                                           eta_min = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
